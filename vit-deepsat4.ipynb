{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14231,"sourceType":"datasetVersion","datasetId":9970},{"sourceId":8572381,"sourceType":"datasetVersion","datasetId":5125892}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T18:24:00.117227Z","iopub.execute_input":"2024-05-31T18:24:00.117957Z","iopub.status.idle":"2024-05-31T18:24:00.123391Z","shell.execute_reply.started":"2024-05-31T18:24:00.117924Z","shell.execute_reply":"2024-05-31T18:24:00.122191Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#  !conda install -c conda-forge vit-pytorch -y","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.125268Z","iopub.execute_input":"2024-05-31T18:24:00.125591Z","iopub.status.idle":"2024-05-31T18:24:00.140130Z","shell.execute_reply.started":"2024-05-31T18:24:00.125564Z","shell.execute_reply":"2024-05-31T18:24:00.139138Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom vit_pytorch import ViT","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.141825Z","iopub.execute_input":"2024-05-31T18:24:00.142202Z","iopub.status.idle":"2024-05-31T18:24:00.152514Z","shell.execute_reply.started":"2024-05-31T18:24:00.142171Z","shell.execute_reply":"2024-05-31T18:24:00.151645Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Define custom dataset\nclass Sat4Dataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        image = self.images[idx].astype(np.float32)\n        label = self.labels[idx].astype(np.int64)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.153477Z","iopub.execute_input":"2024-05-31T18:24:00.153711Z","iopub.status.idle":"2024-05-31T18:24:00.164781Z","shell.execute_reply.started":"2024-05-31T18:24:00.153691Z","shell.execute_reply":"2024-05-31T18:24:00.164012Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess data\ndef image_processing(df_x):\n    reshaped_X = df_x.values.reshape(-1, 28, 28, 4).astype(float)\n    reshaped_X_new = reshaped_X / 255.0\n    reshaped_X_rgb = reshaped_X_new[:, :, :, :3]\n    return reshaped_X_rgb","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.166932Z","iopub.execute_input":"2024-05-31T18:24:00.167277Z","iopub.status.idle":"2024-05-31T18:24:00.175751Z","shell.execute_reply.started":"2024-05-31T18:24:00.167247Z","shell.execute_reply":"2024-05-31T18:24:00.174965Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def label_processing(df_y):\n    df_y['Labels'] = \"NA\"\n    for ix in range(len(df_y)):\n        if df_y.iloc[ix, 0] == 1:\n            df_y.iloc[ix, 4] = \"Barren Land\"\n        elif df_y.iloc[ix, 1] == 1:\n            df_y.iloc[ix, 4] = \"Trees\"\n        elif df_y.iloc[ix, 2] == 1:\n            df_y.iloc[ix, 4] = \"Grassland\"\n        else:\n            df_y.iloc[ix, 4] = \"None\"\n    df_y = df_y['Labels']\n    label_map = {\"Barren Land\": 0, \"Trees\": 1, \"Grassland\": 2, \"None\": 3}\n    labels = df_y.map(label_map).values\n    return labels","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.177024Z","iopub.execute_input":"2024-05-31T18:24:00.177757Z","iopub.status.idle":"2024-05-31T18:24:00.191783Z","shell.execute_reply.started":"2024-05-31T18:24:00.177726Z","shell.execute_reply":"2024-05-31T18:24:00.190812Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/deepsat4-subsets/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.192982Z","iopub.execute_input":"2024-05-31T18:24:00.193531Z","iopub.status.idle":"2024-05-31T18:24:00.202249Z","shell.execute_reply.started":"2024-05-31T18:24:00.193496Z","shell.execute_reply":"2024-05-31T18:24:00.201437Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df_x_train = pd.read_csv(path + \"chunk_x_train_1.csv\")\ndf_y_train = pd.read_csv(path + \"chunk_y_train_1.csv\")\ndf_x_test = pd.read_csv(path + \"chunk_x_test_1.csv\")\ndf_y_test = pd.read_csv(path + \"chunk_y_test_1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:00.203205Z","iopub.execute_input":"2024-05-31T18:24:00.203448Z","iopub.status.idle":"2024-05-31T18:24:28.080339Z","shell.execute_reply.started":"2024-05-31T18:24:00.203427Z","shell.execute_reply":"2024-05-31T18:24:28.079505Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"reshaped_x_train_rgb = image_processing(df_x_train)\ntrain_labels = label_processing(df_y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:28.082960Z","iopub.execute_input":"2024-05-31T18:24:28.083270Z","iopub.status.idle":"2024-05-31T18:24:39.118476Z","shell.execute_reply.started":"2024-05-31T18:24:28.083245Z","shell.execute_reply":"2024-05-31T18:24:39.117643Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"reshaped_x_test_rgb = image_processing(df_x_test)\ntest_labels = label_processing(df_y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:39.119888Z","iopub.execute_input":"2024-05-31T18:24:39.120574Z","iopub.status.idle":"2024-05-31T18:24:41.317039Z","shell.execute_reply.started":"2024-05-31T18:24:39.120541Z","shell.execute_reply":"2024-05-31T18:24:41.316114Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"print(\"Unique train labels:\", np.unique(train_labels))\nprint(\"Unique test labels:\", np.unique(test_labels))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.318424Z","iopub.execute_input":"2024-05-31T18:24:41.318773Z","iopub.status.idle":"2024-05-31T18:24:41.326207Z","shell.execute_reply.started":"2024-05-31T18:24:41.318746Z","shell.execute_reply":"2024-05-31T18:24:41.325012Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Unique train labels: [0 1 2 3]\nUnique test labels: [0 1 2 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.327722Z","iopub.execute_input":"2024-05-31T18:24:41.328514Z","iopub.status.idle":"2024-05-31T18:24:41.337669Z","shell.execute_reply.started":"2024-05-31T18:24:41.328468Z","shell.execute_reply":"2024-05-31T18:24:41.336506Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"train_dataset = Sat4Dataset(reshaped_x_train_rgb, train_labels, transform)\ntest_dataset = Sat4Dataset(reshaped_x_test_rgb, test_labels, transform)\ntrain_size = len(train_dataset)\ntest_size = len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.338951Z","iopub.execute_input":"2024-05-31T18:24:41.339270Z","iopub.status.idle":"2024-05-31T18:24:41.351507Z","shell.execute_reply.started":"2024-05-31T18:24:41.339243Z","shell.execute_reply":"2024-05-31T18:24:41.350498Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.353028Z","iopub.execute_input":"2024-05-31T18:24:41.353931Z","iopub.status.idle":"2024-05-31T18:24:41.369526Z","shell.execute_reply.started":"2024-05-31T18:24:41.353892Z","shell.execute_reply":"2024-05-31T18:24:41.368374Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Check if GPU is available and set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.370886Z","iopub.execute_input":"2024-05-31T18:24:41.371206Z","iopub.status.idle":"2024-05-31T18:24:41.384597Z","shell.execute_reply.started":"2024-05-31T18:24:41.371180Z","shell.execute_reply":"2024-05-31T18:24:41.383564Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize ViT model, loss function, and optimizer\nmodel = ViT(\n    image_size = 224,\n    patch_size = 32,\n    num_classes = 4,\n    dim = 1024,\n    depth = 6,\n    heads = 16,\n    mlp_dim = 2048,\n    dropout = 0.1,\n    emb_dropout = 0.1\n).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.386014Z","iopub.execute_input":"2024-05-31T18:24:41.386713Z","iopub.status.idle":"2024-05-31T18:24:41.867256Z","shell.execute_reply.started":"2024-05-31T18:24:41.386684Z","shell.execute_reply":"2024-05-31T18:24:41.866248Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:24:41.870627Z","iopub.execute_input":"2024-05-31T18:24:41.871216Z","iopub.status.idle":"2024-05-31T18:56:40.258139Z","shell.execute_reply.started":"2024-05-31T18:24:41.871189Z","shell.execute_reply":"2024-05-31T18:56:40.257132Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 0.7463813611613516\nEpoch 2/10, Loss: 0.695645830858394\nEpoch 3/10, Loss: 0.7161111665122649\nEpoch 4/10, Loss: 0.6833347265449021\nEpoch 5/10, Loss: 0.7413558715673358\nEpoch 6/10, Loss: 0.7665075421180871\nEpoch 7/10, Loss: 0.7711625590806117\nEpoch 8/10, Loss: 0.7887809921408553\nEpoch 9/10, Loss: 0.7648241600721998\nEpoch 10/10, Loss: 0.770051057762502\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ny_true = []\ny_pred = []\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\n# Confusion matrix and classification report\nprint(confusion_matrix(y_true, y_pred))\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:56:40.259534Z","iopub.execute_input":"2024-05-31T18:56:40.259851Z","iopub.status.idle":"2024-05-31T18:57:00.318976Z","shell.execute_reply.started":"2024-05-31T18:56:40.259811Z","shell.execute_reply":"2024-05-31T18:57:00.318090Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"[[2292    1  242  120]\n [   0  795   20 1199]\n [ 672   17  836  325]\n [ 104  503  187 2687]]\n              precision    recall  f1-score   support\n\n           0       0.75      0.86      0.80      2655\n           1       0.60      0.39      0.48      2014\n           2       0.65      0.45      0.53      1850\n           3       0.62      0.77      0.69      3481\n\n    accuracy                           0.66     10000\n   macro avg       0.66      0.62      0.62     10000\nweighted avg       0.66      0.66      0.65     10000\n\n","output_type":"stream"}]}]}