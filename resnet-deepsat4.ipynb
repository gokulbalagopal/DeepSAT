{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14231,"sourceType":"datasetVersion","datasetId":9970},{"sourceId":8572381,"sourceType":"datasetVersion","datasetId":5125892}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T17:50:34.115390Z","iopub.execute_input":"2024-05-31T17:50:34.115826Z","iopub.status.idle":"2024-05-31T17:50:34.120524Z","shell.execute_reply.started":"2024-05-31T17:50:34.115800Z","shell.execute_reply":"2024-05-31T17:50:34.119594Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms, models\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport scipy","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.125815Z","iopub.execute_input":"2024-05-31T17:50:34.126104Z","iopub.status.idle":"2024-05-31T17:50:34.137100Z","shell.execute_reply.started":"2024-05-31T17:50:34.126081Z","shell.execute_reply":"2024-05-31T17:50:34.136329Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n\n# Define custom dataset\nclass Sat4Dataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        image = self.images[idx].astype(np.float32)\n        label = self.labels[idx].astype(np.int64)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.138764Z","iopub.execute_input":"2024-05-31T17:50:34.139061Z","iopub.status.idle":"2024-05-31T17:50:34.147918Z","shell.execute_reply.started":"2024-05-31T17:50:34.139038Z","shell.execute_reply":"2024-05-31T17:50:34.147004Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained ResNet and modify it for our task\nclass ResNetModel(nn.Module):\n    def __init__(self):\n        super(ResNetModel, self).__init__()\n        self.resnet = models.resnet18(pretrained=True)\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 4)\n    \n    def forward(self, x):\n        return self.resnet(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.149077Z","iopub.execute_input":"2024-05-31T17:50:34.149398Z","iopub.status.idle":"2024-05-31T17:50:34.158313Z","shell.execute_reply.started":"2024-05-31T17:50:34.149368Z","shell.execute_reply":"2024-05-31T17:50:34.157457Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\ndef image_processing(df_x):\n    reshaped_X = df_x.values.reshape(-1, 28, 28, 4).astype(float)\n    reshaped_X_new = reshaped_X / 255.0\n    reshaped_X_rgb = reshaped_X_new[:, :, :, :3]\n    return reshaped_X_rgb\n\ndef label_processing(df_y):\n    df_y['Labels'] = \"NA\"\n    for ix in range(len(df_y)):\n        if df_y.iloc[ix, 0] == 1:\n            df_y.iloc[ix, 4] = \"Barren Land\"\n        elif df_y.iloc[ix, 1] == 1:\n            df_y.iloc[ix, 4] = \"Trees\"\n        elif df_y.iloc[ix, 2] == 1:\n            df_y.iloc[ix, 4] = \"Grassland\"\n        else:\n            df_y.iloc[ix, 4] = \"None\"\n    df_y = df_y['Labels']\n    label_map = {\"Barren Land\": 0, \"Trees\": 1, \"Grassland\": 2, \"None\": 3}\n    labels = df_y.map(label_map).values\n    return labels\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.160393Z","iopub.execute_input":"2024-05-31T17:50:34.160649Z","iopub.status.idle":"2024-05-31T17:50:34.173752Z","shell.execute_reply.started":"2024-05-31T17:50:34.160628Z","shell.execute_reply":"2024-05-31T17:50:34.173038Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/deepsat4-subsets/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.174624Z","iopub.execute_input":"2024-05-31T17:50:34.174918Z","iopub.status.idle":"2024-05-31T17:50:34.184664Z","shell.execute_reply.started":"2024-05-31T17:50:34.174877Z","shell.execute_reply":"2024-05-31T17:50:34.183900Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_x_train = pd.read_csv(path + \"chunk_x_train_1.csv\")\ndf_y_train = pd.read_csv(path + \"chunk_y_train_1.csv\")\ndf_x_test = pd.read_csv(path + \"chunk_x_test_1.csv\")\ndf_y_test = pd.read_csv(path + \"chunk_y_test_1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:50:34.185899Z","iopub.execute_input":"2024-05-31T17:50:34.186186Z","iopub.status.idle":"2024-05-31T17:51:01.234291Z","shell.execute_reply.started":"2024-05-31T17:50:34.186164Z","shell.execute_reply":"2024-05-31T17:51:01.233181Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"reshaped_x_train_rgb = image_processing(df_x_train)\ntrain_labels = label_processing(df_y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:01.235629Z","iopub.execute_input":"2024-05-31T17:51:01.236029Z","iopub.status.idle":"2024-05-31T17:51:12.298526Z","shell.execute_reply.started":"2024-05-31T17:51:01.235995Z","shell.execute_reply":"2024-05-31T17:51:12.297713Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"reshaped_x_test_rgb = image_processing(df_x_test)\ntest_labels = label_processing(df_y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:12.299711Z","iopub.execute_input":"2024-05-31T17:51:12.300079Z","iopub.status.idle":"2024-05-31T17:51:14.440782Z","shell.execute_reply.started":"2024-05-31T17:51:12.300047Z","shell.execute_reply":"2024-05-31T17:51:14.440008Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(\"Unique train labels:\", np.unique(train_labels))\nprint(\"Unique test labels:\", np.unique(test_labels))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:14.443348Z","iopub.execute_input":"2024-05-31T17:51:14.443705Z","iopub.status.idle":"2024-05-31T17:51:14.449748Z","shell.execute_reply.started":"2024-05-31T17:51:14.443665Z","shell.execute_reply":"2024-05-31T17:51:14.448856Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Unique train labels: [0 1 2 3]\nUnique test labels: [0 1 2 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:14.450979Z","iopub.execute_input":"2024-05-31T17:51:14.451236Z","iopub.status.idle":"2024-05-31T17:51:14.460615Z","shell.execute_reply.started":"2024-05-31T17:51:14.451215Z","shell.execute_reply":"2024-05-31T17:51:14.459895Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_dataset = Sat4Dataset(reshaped_x_train_rgb, train_labels, transform)\ntest_dataset = Sat4Dataset(reshaped_x_test_rgb, test_labels, transform)\ntrain_size = len(train_dataset)\ntest_size = len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:14.461602Z","iopub.execute_input":"2024-05-31T17:51:14.461947Z","iopub.status.idle":"2024-05-31T17:51:14.471890Z","shell.execute_reply.started":"2024-05-31T17:51:14.461914Z","shell.execute_reply":"2024-05-31T17:51:14.471105Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:14.472860Z","iopub.execute_input":"2024-05-31T17:51:14.473133Z","iopub.status.idle":"2024-05-31T17:51:14.486903Z","shell.execute_reply.started":"2024-05-31T17:51:14.473111Z","shell.execute_reply":"2024-05-31T17:51:14.486061Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Check if GPU is available and set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:51:14.487971Z","iopub.execute_input":"2024-05-31T17:51:14.488340Z","iopub.status.idle":"2024-05-31T17:51:14.502973Z","shell.execute_reply.started":"2024-05-31T17:51:14.488307Z","shell.execute_reply":"2024-05-31T17:51:14.502152Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize model, loss function, and optimizer\nmodel = ResNetModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:53:49.996230Z","iopub.execute_input":"2024-05-31T17:53:49.996941Z","iopub.status.idle":"2024-05-31T17:53:50.251370Z","shell.execute_reply.started":"2024-05-31T17:53:49.996907Z","shell.execute_reply":"2024-05-31T17:53:50.250417Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T17:53:52.667833Z","iopub.execute_input":"2024-05-31T17:53:52.668718Z","iopub.status.idle":"2024-05-31T18:16:26.231646Z","shell.execute_reply.started":"2024-05-31T17:53:52.668689Z","shell.execute_reply":"2024-05-31T18:16:26.230609Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 0.09784566311609617\nEpoch 2/10, Loss: 0.05030644109310068\nEpoch 3/10, Loss: 0.03734261839734087\nEpoch 4/10, Loss: 0.033703596977799635\nEpoch 5/10, Loss: 0.02256792621347485\nEpoch 6/10, Loss: 0.025355051814895117\nEpoch 7/10, Loss: 0.021344313670517034\nEpoch 8/10, Loss: 0.01587795396662469\nEpoch 9/10, Loss: 0.0186504463507661\nEpoch 10/10, Loss: 0.013325952854656885\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ny_true = []\ny_pred = []\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\n# Confusion matrix and classification report\nprint(confusion_matrix(y_true, y_pred))\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T18:16:42.143998Z","iopub.execute_input":"2024-05-31T18:16:42.144403Z","iopub.status.idle":"2024-05-31T18:16:58.350398Z","shell.execute_reply.started":"2024-05-31T18:16:42.144363Z","shell.execute_reply":"2024-05-31T18:16:58.349366Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[[2625    0   28    2]\n [   0 1990   23    1]\n [   8    3 1839    0]\n [   3    0    0 3478]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99      2655\n           1       1.00      0.99      0.99      2014\n           2       0.97      0.99      0.98      1850\n           3       1.00      1.00      1.00      3481\n\n    accuracy                           0.99     10000\n   macro avg       0.99      0.99      0.99     10000\nweighted avg       0.99      0.99      0.99     10000\n\n","output_type":"stream"}]}]}